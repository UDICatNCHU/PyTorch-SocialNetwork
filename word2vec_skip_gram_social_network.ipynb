{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec skip-gram@social network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UDICatNCHU/PyTorch-SocialNetwork/blob/master/word2vec_skip_gram_social_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJvhdHnJsL4Q",
        "colab_type": "text"
      },
      "source": [
        "# 手刻版 Hand-Crafted Word2Vec (Skip-gram version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP45bTGBO-oB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.functional as F\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ps2XL34PHKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [\n",
        "    'he is a king',\n",
        "    'she is a queen',\n",
        "    'he is a man',\n",
        "    'she is a woman',\n",
        "    'warsaw is poland capital',\n",
        "    'berlin is germany capital',\n",
        "    'paris is france capital',   \n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuHa7LMJPMQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_corpus(corpus):\n",
        "    tokens = [x.split() for x in corpus]\n",
        "    return tokens\n",
        "\n",
        "tokenized_corpus = tokenize_corpus(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUR0-Mp9PQ3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = []\n",
        "for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "        if token not in vocabulary:\n",
        "            vocabulary.append(token)\n",
        "\n",
        "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
        "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
        "\n",
        "vocabulary_size = len(vocabulary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Io55m5LP5zn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "b5726444-15a5-47e3-88a4-8ebb8d312ead"
      },
      "source": [
        "idx2word"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'he',\n",
              " 1: 'is',\n",
              " 2: 'a',\n",
              " 3: 'king',\n",
              " 4: 'she',\n",
              " 5: 'queen',\n",
              " 6: 'man',\n",
              " 7: 'woman',\n",
              " 8: 'warsaw',\n",
              " 9: 'poland',\n",
              " 10: 'capital',\n",
              " 11: 'berlin',\n",
              " 12: 'germany',\n",
              " 13: 'paris',\n",
              " 14: 'france'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzW1SWO2PUl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window_size = 2\n",
        "idx_pairs = []\n",
        "# for each sentence\n",
        "for sentence in tokenized_corpus:\n",
        "    indices = [word2idx[word] for word in sentence]\n",
        "    # for each word, threated as center word\n",
        "    for center_word_pos in range(len(indices)):\n",
        "        # for each window position\n",
        "        for w in range(-window_size, window_size + 1):\n",
        "            context_word_pos = center_word_pos + w\n",
        "            # make soure not jump out sentence\n",
        "            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
        "                continue\n",
        "            context_word_idx = indices[context_word_pos]\n",
        "            idx_pairs.append((indices[center_word_pos], context_word_idx))\n",
        "\n",
        "idx_pairs = np.array(idx_pairs) # it will be useful to have this as numpy array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB7YtwIOPdYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ae9c11b6-259a-4e53-bc2e-4f4c2be22752"
      },
      "source": [
        "idx_pairs[:5]"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [0, 2],\n",
              "       [1, 0],\n",
              "       [1, 2],\n",
              "       [1, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6utNTfMl49DF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "1ceb7337-13ad-4f00-9c60-e08ff645cf13"
      },
      "source": [
        "for item in idx_pairs[:10]:\n",
        "  print( idx2word[item[0]], idx2word[item[1]])"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "he is\n",
            "he a\n",
            "is he\n",
            "is a\n",
            "is king\n",
            "a he\n",
            "a is\n",
            "a king\n",
            "king is\n",
            "king a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9syz6ZdS4IQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_input_layer(word_idx):\n",
        "    x = torch.zeros(vocabulary_size, dtype=torch.float)\n",
        "    x[word_idx] = 1.0\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wrKkwuRP4E8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "0710f2c1-2cb1-48b6-92d1-ece30375ebe4"
      },
      "source": [
        "embedding_dims = 5\n",
        "W1 = torch.rand(vocabulary_size, embedding_dims, requires_grad=True)\n",
        "W2 = torch.rand(embedding_dims, vocabulary_size, requires_grad=True)\n",
        "num_epochs = 100\n",
        "learning_rate = 0.0001\n",
        "\n",
        "for epo in range(num_epochs):\n",
        "    loss_val = 0\n",
        "    for data, target in idx_pairs:\n",
        "        x = get_input_layer(data)\n",
        "        y_true = torch.tensor(np.array([target]), dtype=torch.long)\n",
        "        z1 = torch.matmul(x, W1)\n",
        "        z2 = torch.matmul(z1, W2)\n",
        "        loss = F.cross_entropy(z2.view(1,-1), y_true)\n",
        "        loss_val += loss.item()\n",
        "        loss.backward()\n",
        "        W1.data -= learning_rate * W1.grad\n",
        "        W2.data -= learning_rate * W2.grad\n",
        "        W1.grad.data.zero_()\n",
        "        W2.grad.data.zero_()\n",
        "    if epo % 10 == 0:    \n",
        "        print(f'Loss at epo {epo}: {loss.item()}')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epo 0: 3.1296887397766113\n",
            "Loss at epo 10: 3.1275291442871094\n",
            "Loss at epo 20: 3.1254820823669434\n",
            "Loss at epo 30: 3.123535633087158\n",
            "Loss at epo 40: 3.1216793060302734\n",
            "Loss at epo 50: 3.1199183464050293\n",
            "Loss at epo 60: 3.1182594299316406\n",
            "Loss at epo 70: 3.116689682006836\n",
            "Loss at epo 80: 3.1152024269104004\n",
            "Loss at epo 90: 3.1138038635253906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QozhI246S2vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = torch.tensor(np.array([1,2]), dtype=torch.long)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZbHS0OOeNjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92f02330-c13a-4e0f-f712-b42e0a5e772c"
      },
      "source": [
        ""
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPAEoKKEnxJB",
        "colab_type": "text"
      },
      "source": [
        "# 使用Pytorch Framework版 Word2Vec (Skip-gram version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tELrk-SieOoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1944004f-59dc-4fbb-eb48-8c55e2f3ec4e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe7974536b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TXgRUfUo5_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7986e83f-aee7-4968-a344-8eeb24dd6a8e"
      },
      "source": [
        "len(vocabulary)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_hV-dEVirXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "140f5127-f8e6-42ce-d44f-4a7d804e1016"
      },
      "source": [
        "class Word2Vec_SkipGram(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(Word2Vec_SkipGram, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs)\n",
        "        out = self.linear(embeds)\n",
        "        return out\n",
        "\n",
        "\n",
        "losses = []\n",
        "EMBEDDING_DIM = 10\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "model = Word2Vec_SkipGram(len(vocabulary), EMBEDDING_DIM)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5):\n",
        "    total_loss = 0\n",
        "    for data, target in idx_pairs:\n",
        "        data_input = torch.tensor([data], dtype=torch.long)\n",
        "        predicted = model(data_input)\n",
        "        label = torch.tensor([target], dtype=torch.long)   \n",
        "        \n",
        "        optimizer.zero_grad()     \n",
        "        loss = F.cross_entropy(predicted, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(loss.item())"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.471090316772461\n",
            "2.433135747909546\n",
            "2.3987107276916504\n",
            "2.3689889907836914\n",
            "2.3439688682556152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "561WBx3B0Ve_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "474e9638-c800-4c1d-c611-638ea04e87eb"
      },
      "source": [
        "idx2word[3]"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'king'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PRdFFRJ0ogj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "77687d40-39dc-4a82-f9a0-5e84e80a0d2a"
      },
      "source": [
        "idx2word[5]"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'queen'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILGgxp8A1Igg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b310787d-0955-4f0d-b4b0-ea9cb29fc906"
      },
      "source": [
        "word2idx[\"king\"]"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB6Ux6fFnp9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lookup_tensors = torch.tensor([word2idx[\"king\"], word2idx[\"queen\"]] ,dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f9_gpD4vs6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "39d72eb6-0b7c-4439-c786-280b672a12e7"
      },
      "source": [
        "lookup_tensors"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0d11KzW19Q7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "4dc241fb-e8ea-4899-e994-4ad353290ea4"
      },
      "source": [
        "model(lookup_tensor)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.2777,  5.4239,  5.4351, -1.2188, -1.1558, -1.3492, -1.5852, -1.3467,\n",
              "         -1.3630, -0.2604, -2.4192, -3.2783,  0.0565, -2.5430, -5.3278],\n",
              "        [-2.0963,  5.9476,  5.9539, -2.5179, -2.4708, -2.5742, -3.3025, -1.9582,\n",
              "         -2.0920, -2.2185,  0.8063, -0.5378, -0.7538,  0.8653, -1.0555]],\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF0y1RDvvPii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector_for_king = model(lookup_tensor).data[0]\n",
        "vector_for_queen = model(lookup_tensor).data[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYecsMlR2Vo_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "93e43fa0-24e1-4129-8c6c-13a442a3729f"
      },
      "source": [
        "vector_for_king"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.2777,  5.4239,  5.4351, -1.2188, -1.1558, -1.3492, -1.5852, -1.3467,\n",
              "        -1.3630, -0.2604, -2.4192, -3.2783,  0.0565, -2.5430, -5.3278])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ7bAaSo2DF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b2ad3b7a-2327-4a94-b6b3-b424a48123b1"
      },
      "source": [
        "vector_for_queen"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.0963,  5.9476,  5.9539, -2.5179, -2.4708, -2.5742, -3.3025, -1.9582,\n",
              "        -2.0920, -2.2185,  0.8063, -0.5378, -0.7538,  0.8653, -1.0555])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DODNjtCgvTNj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3cd96ed4-2da1-473f-c95d-896754bbf7ac"
      },
      "source": [
        "F.cosine_similarity(vector_for_king.view(1,-1), vector_for_queen.view(1,-1))"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7455])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeT18vWG2AzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRG-wNx53kb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC9id-iq3w4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t47a7Em4LlF",
        "colab_type": "text"
      },
      "source": [
        "# Excercise  Word2vec based on Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMtVvzkH4LRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a4834364-1982-45a7-e9c1-94ee3a4b53aa"
      },
      "source": [
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
        "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern of rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
        "\n",
        "# By deriving a set from `raw_text`, we deduplicate the array\n",
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "data = []\n",
        "for i in range(2, len(raw_text) - 2):\n",
        "    context = [raw_text[i - 2], raw_text[i - 1],\n",
        "               raw_text[i + 1], raw_text[i + 2]]\n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))\n",
        "print(data[:5])\n",
        "\n",
        "\n",
        "class CBOW(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        pass\n",
        "\n",
        "# create your model and train.  here are some functions to help you make\n",
        "# the data ready for use by your module\n",
        "\n",
        "\n",
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "\n",
        "make_context_vector(data[0][0], word_to_ix)  # example"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([29, 28, 15, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9rm9RYv4mcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}